"""This script takes a combined table of TR genotypes (generated by the combine_str_json_to_tsv script) and
filters it to the N most expanded genotypes per locus, based on either the long allele, or on the short allele
(for recessive searches). The output is a table with the same columns as the input, but with only the N most expanded
genotypes per locus.
The input table must have a "LocusId" column and a "Num Repeats: Allele 1" and "Num Repeats: Allele 2" column. If
--min-purity is specified, it should also have an "AllelePurity" column with comma-separated purity values for each
allele.
"""

import argparse
import collections
import os
import pandas as pd

def parse_args():
	parser = argparse.ArgumentParser()
	parser.add_argument("-n", type=int, default=50, help="Number of genotypes to keep per locus")
	parser.add_argument("-o", "--output-prefix", help="Output TSV path")
	parser.add_argument("--min-q", type=float, help="Optionally pre-filter alleles by Q score")
	parser.add_argument("--min-purity", type=float, help="Optionally pre-filter alleles by purity")
	parser.add_argument("--exclude-sample-ids", help="Path of file with sample IDs to exclude (one per line)")
	group = parser.add_mutually_exclusive_group()
	group.add_argument("--by-long-allele", action="store_true", help="Filter by long allele")
	group.add_argument("--by-short-allele", action="store_true", help="Filter by short allele")
	parser.add_argument("--discard-non-polymorphic-loci", action="store_true", help="Discard loci where all alleles are "
						"within +/-2 repeats of the mode allele size")
	parser.add_argument("--max-entries-per-histogram", type=int,
						help="If specified, the allele histogram strings will include no more than this many of the "
							 "largest alleles. This can keep these strings from taking up too much space.")
	parser.add_argument("input_table", help="Input table with genotypes to filter")

	args = parser.parse_args()

	if not args.input_table.endswith(".tsv") and not args.input_table.endswith(".tsv.gz"):
		parser.error("Input table must have a .tsv or .tsv.gz extension")

	if not os.path.isfile(args.input_table):
		parser.error(f"Input table not found: {args.input_table}")

	if args.exclude_sample_ids and not os.path.isfile(args.exclude_sample_ids):
		parser.error(f"Exclude sample IDs file not found: {args.exclude_sample_ids}")

	if not args.output_prefix:
		args.output_prefix = args.input_table.replace(".tsv", "").replace(".gz", "")

	return args


def discard_non_polymorphic_loci(df, locus_id_to_histogram_dict):
	total = len(df)
	print("Discarding loci where all alleles are within +/-2 repeats of the mode allele size")
	loci_before = len(locus_id_to_histogram_dict)
	loci_to_discard = set()
	for locus_id, histogram_dict in locus_id_to_histogram_dict.items():
		mode_repeat_number = max(histogram_dict, key=histogram_dict.get)
		if all(abs(repeat_number - mode_repeat_number) <= 2 for repeat_number in histogram_dict):
			loci_to_discard.add(locus_id)
	df = df[~df["LocusId"].isin(loci_to_discard)]

	loci_after = len(set(df["LocusId"]))
	print(f"Kept {len(df):,d} out of {total:,d} ({len(df) / total:.1%}) rows and "
		  f"{loci_after} out of {loci_before} loci ({loci_after / loci_before:.1%}) "
		  f"after filtering out non-polymorphic loci")

	return df


def filter_by_purity(min_purity_threshold, both_alleles=False):
	def filter_func(allele_purity_values):
		if both_alleles:
			return all(p != "." and float(p) >= min_purity_threshold for p in allele_purity_values.split(","))
		else:
			allele_purity_values = allele_purity_values.split(",")
			p = allele_purity_values[-1]
			return p != "." and float(p) >= min_purity_threshold

	return filter_func


def convert_allele_histogram_dict_to_string(allele_histogram_dict, max_entries=None):
	if max_entries == 0:
		return ""
	data = sorted(allele_histogram_dict.items())
	if max_entries is not None:
		data = data[-max_entries:]
	return ",".join(f"{repeat_number}x:{allele_count}" for repeat_number, allele_count in data)


def get_stdev_of_allele_histogram_dict(allele_histogram_dict):
	total = sum(allele_histogram_dict.values())
	mean = sum(repeat_number * count for repeat_number, count in allele_histogram_dict.items()) / total
	return (sum((repeat_number - mean) ** 2 * count for repeat_number, count in allele_histogram_dict.items()) / total) ** 0.5


def compute_locus_id_to_allele_histogram_dict(df):
	locus_id_to_histogram_dict = collections.defaultdict(collections.Counter)
	for locus_id, locus_df in df.groupby("LocusId"):
		for c in "Num Repeats: Allele 1", "Num Repeats: Allele 2":
			for allele_size in locus_df[c]:
				if pd.isna(allele_size):
					continue
				locus_id_to_histogram_dict[locus_id][int(allele_size)] += 1
	return locus_id_to_histogram_dict


def add_allele_histogram(df, locus_id_to_histogram_dict, histogram_key, stdev_key, max_entries=None):
	locus_id_to_stdev = {}
	for locus_id, histogram_dict in locus_id_to_histogram_dict.items():
		locus_id_to_stdev[locus_id] = get_stdev_of_allele_histogram_dict(histogram_dict)
	df[stdev_key] = df["LocusId"].map(locus_id_to_stdev)

	if max_entries is None or max_entries > 0:
		locus_id_to_histogram_string = {}
		for locus_id, histogram_dict in locus_id_to_histogram_dict.items():
			locus_id_to_histogram_string[locus_id] = convert_allele_histogram_dict_to_string(
				histogram_dict, max_entries=max_entries)
		df[histogram_key] = df["LocusId"].map(locus_id_to_histogram_string)


def process_table(df, args, by_long_allele=True):
	total = len(df)

	print(f"Computing allele frequency histograms")
	locus_id_to_histogram_dict = compute_locus_id_to_allele_histogram_dict(df)
	if args.min_purity:
		add_allele_histogram(
			df, locus_id_to_histogram_dict, "AlleleHistBeforePurityFilter", "AlleleStdevBeforePurityFilter",
			max_entries=args.max_entries_per_histogram)

		if by_long_allele:
			print(f"Filtering to genotypes with long allele purity of at least {args.min_purity}")
			df = df[df["AllelePurity"].apply(filter_by_purity(args.min_purity, both_alleles=False))]
		else:
			print(f"Filtering to genotypes where both alleles have purity of at least {args.min_purity}")
			df = df[df["AllelePurity"].apply(filter_by_purity(args.min_purity, both_alleles=True))]

		print(f"Kept {len(df):,d} out of {total:,d} ({len(df) / total:.1%}) rows after filtering by purity")

		locus_id_to_histogram_dict = compute_locus_id_to_allele_histogram_dict(df)
		add_allele_histogram(df, locus_id_to_histogram_dict, "AlleleHist", "AlleleStdev",
							 max_entries=args.max_entries_per_histogram)
	else:
		add_allele_histogram(df, locus_id_to_histogram_dict, "AlleleHist", "AlleleStdev",
							 max_entries=args.max_entries_per_histogram)

	print(f"Sorting by {'long' if by_long_allele else 'short'} allele")
	if by_long_allele:
		df.sort_values(["Num Repeats: Allele 2", "Num Repeats: Allele 1"], ascending=False, inplace=True)
	else:
		df.sort_values(["Num Repeats: Allele 1", "Num Repeats: Allele 2"], ascending=False, inplace=True)

	print(f"Filtering to top {args.n} genotypes per locus")
	df = df.groupby("LocusId").head(args.n)
	print(f"Kept {len(df):,d} out of {total:,d} ({len(df) / total:.1%}) rows after filtering to top {args.n} genotypes per locus")

	output_path = args.output_prefix
	if args.min_purity:
		output_path += f".purity_{args.min_purity}"
	output_path += f".top_{args.n}_by_{'long' if by_long_allele else 'short'}_allele.tsv.gz"
	df.to_csv(output_path, sep="\t", index=False)
	print(f"Wrote {len(df):,d} rows to {output_path}")


def main():
	args = parse_args()
	print(f"Parsing {args.input_table}")
	df = pd.read_table(args.input_table)
	print(f"Parsed {len(df):,d} rows and {len(set(df.LocusId)):,d} loci from {args.input_table}")

	if args.exclude_sample_ids:
		total = len(df)
		exclude_sample_ids = set(pd.read_table(args.exclude_sample_ids, names=["SampleId"]).SampleId)
		missing_sample_ids = exclude_sample_ids - set(df["SampleId"])
		if missing_sample_ids:
			raise ValueError(f"{len(missing_sample_ids):,d} out of {len(exclude_sample_ids):,d} excluded sample IDs "
				  f"not found in input table: {missing_sample_ids}")
		print(f"Filtering out {len(exclude_sample_ids):,d} excluded sample IDs")
		df = df[~df["SampleId"].isin(exclude_sample_ids)]
		print(f"Kept {len(df):,d} out of {total:,d} ({len(df) / total:.1%}) rows after filtering out excluded sample IDs")

	if args.discard_non_polymorphic_loci:
		locus_id_to_histogram_dict = compute_locus_id_to_allele_histogram_dict(df)
		df = discard_non_polymorphic_loci(df, locus_id_to_histogram_dict)

	if args.min_q:
		total = len(df)
		print(f"Filtering to genotypes with Q score of at least {args.min_q}")
		df = df[(df["Q: Allele 1"] >= args.min_q) & (df["Q: Allele 2"] >= args.min_q)]
		print(f"Kept {len(df):,d} out of {total:,d} ({len(df) / total:.1%}) rows after filtering by Q score")

	if args.by_long_allele:
		by_long_allele_settings = [True]
	elif args.by_short_allele:
		by_long_allele_settings = [False]
	else:
		by_long_allele_settings = [True, False]

	for by_long_allele in by_long_allele_settings:
		if len(by_long_allele_settings) > 1:
			print(f"="*80)
			print(f"Processing {args.input_table} with sorting by {'long' if by_long_allele else 'short'} allele")
		process_table(df, args, by_long_allele)

if __name__ == "__main__":
	main()